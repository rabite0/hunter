// Based on https://github.com/jD91mZM2/termplay
// MIT License

use base64;
use image::{DynamicImage, GenericImageView, RgbaImage};

use termion::color::{Bg, Fg, Rgb};
#[cfg(feature = "video")]
use termion::input::TermRead;

#[cfg(feature = "video")]
use gstreamer::prelude::*;
#[cfg(feature = "video")]
use gstreamer_app;

use failure::{format_err, Error};

use std::io::Write;
#[cfg(feature = "video")]
use std::sync::{Arc, RwLock};

pub type MResult<T> = Result<T, Error>;

fn main() -> MResult<()> {
    let args = std::env::args().collect::<Vec<String>>();
    let xsize: usize = args
        .get(1)
        .expect("Provide xsize")
        .parse::<usize>()
        .unwrap();
    let ysize = args.get(2).expect("provide ysize").parse().unwrap();
    let mut xpix = args
        .get(3)
        .expect("provide xsize in pixels")
        .parse::<usize>()
        .unwrap();
    let mut ypix = args
        .get(4)
        .expect("provide ysize in pixels")
        .parse::<usize>()
        .unwrap();
    let cell_ratio = args
        .get(5)
        .expect("Provide cell ratio")
        .parse::<f32>()
        .unwrap();
    let preview_type = args
        .get(6)
        .expect("Provide preview type")
        .parse::<String>()
        .unwrap();
    #[allow(unused_variables)]
    let autoplay = args.get(7).expect("Autoplay?").parse::<bool>().unwrap();
    #[allow(unused_variables)]
    let mute = args.get(8).expect("Muted?").parse::<bool>().unwrap();
    let target = args
        .get(9)
        .expect("Render target?")
        .parse::<String>()
        .unwrap();
    let path = args.get(10).expect("Provide path");

    let target = match target.as_str() {
        #[cfg(feature = "sixel")]
        "sixel" => RenderTarget::Sixel,
        "kitty" => RenderTarget::Kitty,
        "auto" => {
            let term = std::env::var("TERM").unwrap_or(String::from(""));
            match term.as_str() {
                "kitty" => RenderTarget::Kitty,
                #[cfg(feature = "sixel")]
                "xterm" => RenderTarget::Sixel,
                _ => RenderTarget::Unicode,
            }
        }
        _ => RenderTarget::Unicode,
    };

    if target == RenderTarget::Unicode {
        xpix = xsize;
        ypix = ysize * 2;
    }

    let renderer = Renderer::new(target, xsize, ysize, xpix, ypix, cell_ratio);

    let result = match preview_type.as_ref() {
        #[cfg(feature = "video")]
        "video" => video_preview(path, renderer, autoplay, mute),

        "image" => image_preview(path, renderer),

        #[cfg(feature = "video")]
        "audio" => audio_preview(path, autoplay, mute),

        #[cfg(feature = "video")]
        _ => panic!("Available types: video/image/audio"),

        #[cfg(not(feature = "video"))]
        _ => panic!("Available type: image"),
    };

    if result.is_err() {
        println!("{:?}", &result);
        result
    } else {
        Ok(())
    }
}

fn image_preview(path: &str, renderer: Renderer) -> MResult<()> {
    let img = image::open(&path)?;
    let max_size = renderer.max_size_pix(&img);

    let img = img
        .resize_exact(
            max_size.0 as u32,
            max_size.1 as u32,
            image::FilterType::Gaussian,
        )
        .to_rgba();
    renderer.send_image(&img)?;

    Ok(())
}

trait ImgSize {
    fn size(&self) -> MResult<(usize, usize)>;
}

#[cfg(feature = "video")]
impl ImgSize for gstreamer::Sample {
    fn size(&self) -> MResult<(usize, usize)> {
        let size = || {
            let caps = self.as_ref().get_caps()?;
            let caps = caps.get_structure(0)?;
            let width = caps.get::<i32>("width")? as usize;
            let height = caps.get::<i32>("height")? as usize;
            Some((width, height))
        };
        size().ok_or(format_err!("Can't get size from sample!"))
    }
}

impl ImgSize for RgbaImage {
    fn size(&self) -> MResult<(usize, usize)> {
        let width = self.width() as usize;
        let height = self.height() as usize;
        Ok((width, height))
    }
}

impl ImgSize for DynamicImage {
    fn size(&self) -> MResult<(usize, usize)> {
        let width = self.width() as usize;
        let height = self.height() as usize;
        Ok((width, height))
    }
}

#[cfg(feature = "video")]
fn video_preview(path: &String, renderer: Renderer, autoplay: bool, mute: bool) -> MResult<()> {
    let gst = Gstreamer::new(path)?;

    let renderer = Arc::new(RwLock::new(renderer));
    let crenderer = renderer.clone();
    let cgst = gst.clone();
    gst.process_first_frame(&renderer)?;

    gst.appsink.set_callbacks(
        gstreamer_app::AppSinkCallbacks::new()
            .new_sample({
                move |sink| {
                    let renderer = crenderer.clone();
                    let gst = cgst.clone();

                    let sample = match sink.pull_sample() {
                        Some(sample) => sample,
                        None => return Err(gstreamer::FlowError::Eos),
                    };

                    let pos = gst.position();
                    let dur = gst.duration();

                    std::thread::spawn(move || {
                        // This will lock make sure only one frame is being sent
                        // at a time
                        renderer
                            .try_write()
                            .map(|mut r| r.new_frame(sample, pos, dur).unwrap())
                            .map_err(|_| {
                                // But if processing takes too long, reduce rate
                                let rate = gst.get_rate().unwrap();
                                gst.set_rate(rate - 1)
                            })
                            .ok();
                    });

                    Ok(gstreamer::FlowSuccess::Ok)
                }
            })
            .eos({
                move |_| {
                    std::process::exit(0);
                }
            })
            .build(),
    );

    // Flush pipeline and restart with corrent resizing
    gst.stop()?;

    if autoplay {
        gst.start(mute)?;
    } else {
        gst.pause()?;
        gst.send_preroll(&renderer)?;
    }

    read_keys(gst.clone(), Some(renderer))?;

    Ok(())
}

#[cfg(feature = "video")]
fn read_keys(gst: Gstreamer, renderer: Option<Arc<RwLock<Renderer>>>) -> MResult<()> {
    let stdin = std::io::stdin();
    let mut stdin = stdin.lock();

    loop {
        let input = stdin.read_line()?.unwrap_or_else(|| String::from("q"));

        match input.as_str() {
            "q" => return gst.stop(),
            ">" => {
                gst.seek_forward()?;
                renderer.as_ref().map(|r| {
                    if gst.get_state() == gstreamer::State::Paused {
                        gst.send_preroll(&r).unwrap();
                    }
                });
            }
            "<" => {
                gst.seek_backward()?;
                renderer.as_ref().map(|r| {
                    if gst.get_state() == gstreamer::State::Paused {
                        gst.send_preroll(&r).unwrap();
                    }
                });
            }
            "p" => gst.play()?,
            "a" => gst.pause()?,
            "m" => gst.mute()?,
            "u" => gst.unmute()?,
            "xy" => {
                if let Some(ref renderer) = renderer {
                    let xsize = stdin
                        .read_line()?
                        .unwrap_or(String::from("0"))
                        .parse::<usize>()?;
                    let ysize = stdin
                        .read_line()?
                        .unwrap_or(String::from("0"))
                        .parse::<usize>()?;
                    let mut xpix = stdin
                        .read_line()?
                        .unwrap_or(String::from("0"))
                        .parse::<usize>()?;
                    let mut ypix = stdin
                        .read_line()?
                        .unwrap_or(String::from("0"))
                        .parse::<usize>()?;
                    let cell_ratio = stdin
                        .read_line()?
                        .unwrap_or(String::from("0"))
                        .parse::<f32>()?;
                    let mut renderer = renderer
                        .write()
                        .map_err(|_| format_err!("Renderer RwLock failed!"))?;

                    if renderer.target == RenderTarget::Unicode {
                        xpix = xsize;
                        ypix = ysize * 2;
                    }

                    renderer.set_widget_size(xsize, ysize, xpix, ypix, cell_ratio)?;
                    match renderer.last_frame {
                        Some(ref sample) => {
                            let (max_x, max_y) = renderer.max_size_pix(sample);
                            gst.set_scaling(max_x, max_y)?;
                        }
                        _ => {}
                    }
                }
            }
            _ => {}
        }
    }
}

#[cfg(feature = "video")]
pub fn audio_preview(path: &String, autoplay: bool, mute: bool) -> MResult<()> {
    let gst = Gstreamer::new(path)?;
    let tgst = gst.clone();

    // Since events don't work with audio files...
    std::thread::spawn(move || -> MResult<()> {
        let mut last_pos = None;
        let sleep_duration = std::time::Duration::from_millis(50);
        let mut stdout = std::io::stdout();
        loop {
            std::thread::sleep(sleep_duration);
            let gst = tgst.clone();

            let position = gst.position();
            let duration = gst.duration();

            // Just redo loop until position changes
            if last_pos == Some(position) {
                continue;
            }

            last_pos = Some(position);

            // MediaView needs empty line as separator
            writeln!(stdout, "")?;
            // Send height, position and duration
            writeln!(stdout, "0")?;
            writeln!(stdout, "{}", position)?;
            writeln!(stdout, "{}", duration)?;
            stdout.flush()?;
        }
    });

    if autoplay && !mute {
        gst.start(mute)?;
    }

    read_keys(gst, None)?;

    Ok(())
}

#[cfg(feature = "video")]
#[derive(Clone)]
struct Gstreamer {
    player: gstreamer::Element,
    appsink: gstreamer_app::AppSink,
    videorate: gstreamer::Element,
}

#[cfg(feature = "video")]
impl Gstreamer {
    fn new(file: &str) -> MResult<Gstreamer> {
        use gstreamer::{Bin, Element, ElementFactory, GhostPad};
        gstreamer::init()?;

        let player =
            ElementFactory::make("playbin", None).ok_or(format_err!("Can't create playbin"))?;

        let videorate = ElementFactory::make("videorate", None)
            .ok_or(format_err!("Can't create videorate element"))?;

        let sink =
            ElementFactory::make("appsink", None).ok_or(format_err!("Can't create appsink"))?;

        let appsink = sink.clone().downcast::<gstreamer_app::AppSink>().unwrap();

        let elems = &[
            &videorate, //&videoscale,
            &sink,
        ];

        let bin = Bin::new(None);

        bin.add_many(elems)?;
        Element::link_many(elems)?;

        // make input for bin point to first element
        let sink = elems[0].get_static_pad("sink").unwrap();
        let ghost =
            GhostPad::new(Some("sink"), &sink).ok_or(format_err!("Can't create GhostPad"))?;

        ghost.set_active(true)?;
        bin.add_pad(&ghost)?;

        appsink.set_drop(true);
        appsink.set_max_buffers(4);

        videorate.set_property("drop-only", &true)?;
        //videorate.set_property("max-rate", &1)?;

        let uri = format!("file://{}", &file);

        player.set_property("video-sink", &bin.upcast::<gstreamer::Element>())?;
        player.set_property("uri", &uri)?;

        use gstreamer::prelude::*;

        Ok(Gstreamer {
            player,
            appsink,
            videorate,
        })
    }

    pub fn change_format(&self, format: gstreamer::Caps) -> MResult<()> {
        use gstreamer::Element;
        use gstreamer_video::prelude::*;

        let state = self.get_state();
        self.pause()?;

        let appsink = self.appsink.clone().upcast::<Element>();

        Element::unlink_many(&[&self.videorate, &appsink]);

        self.appsink.set_caps(Some(&format));

        Element::link_many(&[&self.videorate, &appsink])?;

        std::thread::sleep(std::time::Duration::from_millis(100));
        self.player.set_state(state)?;

        Ok(())
    }

    pub fn process_first_frame(&self, renderer: &Arc<RwLock<Renderer>>) -> MResult<()> {
        self.pause()?;

        let sample = self
            .appsink
            .pull_preroll()
            .ok_or_else(|| format_err!("Couldn't read first frame!"))?;

        let (max_x, max_y) = renderer
            .read()
            .map_err(|_| format_err!("Failed at locking renderer!"))?
            .max_size_pix(&sample);

        self.set_scaling(max_x, max_y)?;

        Ok(())
    }

    pub fn send_preroll(&self, renderer: &Arc<RwLock<Renderer>>) -> MResult<()> {
        let appsink = self
            .appsink
            .downcast_ref::<gstreamer_app::AppSink>()
            .unwrap();
        let sample = appsink.pull_preroll().unwrap();
        let pos = self.position();
        let dur = self.duration();
        renderer.write().unwrap().new_frame(sample, pos, dur)
    }

    pub fn set_scaling(&self, x: usize, y: usize) -> MResult<()> {
        use gstreamer::Caps;

        let caps = format!("video/x-raw,format=RGBA,width={},height={}", x, y);
        let caps = Caps::from_string(&caps).unwrap();

        self.change_format(caps)
    }

    pub fn get_rate(&self) -> MResult<i32> {
        let rate = self
            .videorate
            .get_property("max-rate")?
            .downcast::<i32>()
            .unwrap()
            .get()
            .ok_or_else(|| format_err!("No video rate???"))?;

        if rate == 2147483647 {
            // Sane defalt fps cap if rendering is too slow
            Ok(30)
        } else {
            Ok(rate)
        }
    }

    pub fn set_rate(&self, rate: i32) -> MResult<()> {
        self.videorate.set_property("max-rate", &rate)?;
        Ok(())
    }

    pub fn position(&self) -> usize {
        self.player
            .query_position::<gstreamer::ClockTime>()
            .map(|p| p.seconds().unwrap_or(0))
            .unwrap_or(0) as usize
    }

    pub fn duration(&self) -> usize {
        self.player
            .query_duration::<gstreamer::ClockTime>()
            .map(|d| d.seconds().unwrap_or(0))
            .unwrap_or(0) as usize
    }

    pub fn set_state(&self, state: gstreamer::State) -> MResult<()> {
        self.player.set_state(state)?;
        // HACK: How to sync properly?
        std::thread::sleep(std::time::Duration::from_millis(100));

        Ok(())
    }

    pub fn pause(&self) -> MResult<()> {
        self.set_state(gstreamer::State::Paused)?;

        Ok(())
    }

    pub fn mute(&self) -> MResult<()> {
        Ok(self.player.set_property("volume", &0.0)?)
    }

    pub fn unmute(&self) -> MResult<()> {
        Ok(self.player.set_property("volume", &1.0)?)
    }

    pub fn get_state(&self) -> gstreamer::State {
        let timeout = gstreamer::ClockTime::from_seconds(1);
        let state = self.player.get_state(timeout);

        state.1
    }

    pub fn start(&self, mute: bool) -> MResult<()> {
        if mute {
            self.mute()?;
        }
        self.play()
    }

    pub fn play(&self) -> MResult<()> {
        self.set_state(gstreamer::State::Playing)
    }

    pub fn stop(&self) -> MResult<()> {
        self.set_state(gstreamer::State::Ready)
    }

    pub fn seek_forward(&self) -> MResult<()> {
        let seek_time = gstreamer::ClockTime::from_seconds(5);
        if let Some(mut time) = self.player.query_position::<gstreamer::ClockTime>() {
            time += seek_time;

            self.player.seek_simple(
                gstreamer::SeekFlags::FLUSH,
                gstreamer::format::GenericFormattedValue::Time(time),
            )?;
        }
        Ok(())
    }

    pub fn seek_backward(&self) -> MResult<()> {
        let seek_time = gstreamer::ClockTime::from_seconds(5);
        if let Some(mut time) = self.player.query_position::<gstreamer::ClockTime>() {
            if time >= seek_time {
                time -= seek_time;
            } else {
                time = gstreamer::ClockTime(Some(0));
            }

            self.player.seek_simple(
                gstreamer::SeekFlags::FLUSH,
                gstreamer::format::GenericFormattedValue::Time(time),
            )?;
        }
        Ok(())
    }
}

trait WithRaw {
    fn with_raw(&self, fun: impl FnOnce(&[u8]) -> MResult<()>) -> MResult<()>;
}

#[cfg(feature = "video")]
impl WithRaw for gstreamer::Sample {
    fn with_raw(&self, fun: impl FnOnce(&[u8]) -> MResult<()>) -> MResult<()> {
        let buffer = self
            .get_buffer()
            .ok_or(format_err!("Couldn't get buffer from frame!"))?;

        let map = buffer
            .map_readable()
            .ok_or(format_err!("Couldn't get buffer from frame!"))?;

        fun(map.as_slice())
    }
}

// Mostly for plain old images, since they come from image::open
impl WithRaw for RgbaImage {
    fn with_raw(&self, fun: impl FnOnce(&[u8]) -> MResult<()>) -> MResult<()> {
        let bytes = self.as_flat_samples();

        fun(bytes.as_slice())
    }
}

#[derive(PartialEq)]
enum RenderTarget {
    Unicode,
    #[cfg(feature = "sixel")]
    Sixel,
    Kitty,
}

impl RenderTarget {
    fn send_image(&self, img: &(impl WithRaw + ImgSize), context: &Renderer) -> MResult<()> {
        match self {
            #[cfg(feature = "sixel")]
            RenderTarget::Sixel => self.print_sixel(img)?,
            RenderTarget::Unicode => self.print_unicode(img)?,
            RenderTarget::Kitty => self.print_kitty(img, context)?,
        }
        Ok(())
    }

    fn print_unicode(&self, img: &(impl WithRaw + ImgSize)) -> MResult<()> {
        let (xsize, _) = img.size()?;

        img.with_raw(move |raw| -> MResult<()> {
            let lines = raw
                .chunks(4 * xsize * 2)
                .map(|two_lines_colors| {
                    let (upper_line, lower_line) = two_lines_colors.split_at(4 * xsize);
                    upper_line
                        .chunks(4)
                        .zip(lower_line.chunks(4))
                        .map(|(upper, lower)| {
                            format!(
                                "{}{}▀{}",
                                Fg(Rgb(upper[0], upper[1], upper[2])),
                                Bg(Rgb(lower[0], lower[1], lower[2])),
                                termion::style::Reset
                            )
                        })
                        .collect::<String>()
                })
                .collect::<Vec<String>>();

            for line in lines {
                println!("{}", line);
            }

            println!("");

            Ok(())
        })
    }

    fn print_kitty(&self, img: &(impl WithRaw + ImgSize), context: &Renderer) -> MResult<()> {
        let (w, h) = context.max_size(img);
        let (img_x, img_y) = img.size()?;

        img.with_raw(move |raw| -> MResult<()> {
            let mut file = std::fs::File::create("/tmp/img.raw.new")?;
            file.write_all(raw)?;
            file.flush()?;
            std::fs::rename("/tmp/img.raw.new", "/tmp/img.raw")?;

            let path = base64::encode("/tmp/img.raw");

            print!("\x1b_Ga=d\x1b\\");
            println!(
                "\x1b_Gf=32,s={},v={},c={},r={},a=T,t=f;{}\x1b\\",
                img_x, img_y, w, h, path
            );
            println!("");

            Ok(())
        })
    }

    #[cfg(feature = "sixel")]
    fn print_sixel(&self, img: &(impl WithRaw + ImgSize)) -> MResult<()> {
        use sixel_rs::encoder::{Encoder, QuickFrameBuilder};
        use sixel_rs::optflags::EncodePolicy;

        let (xpix, ypix) = img.size()?;

        img.with_raw(move |raw| -> MResult<()> {
            let sixfail = |e| format_err!("Sixel failed with: {:?}", e);
            let encoder = Encoder::new().map_err(sixfail)?;

            encoder
                .set_encode_policy(EncodePolicy::Fast)
                .map_err(sixfail)?;

            let frame = QuickFrameBuilder::new()
                .width(xpix)
                .height(ypix)
                .format(sixel_sys::PixelFormat::RGBA8888)
                .pixels(raw.to_vec());

            encoder.encode_bytes(frame).map_err(sixfail)?;

            // No end of line printed by encoder
            println!("");
            println!("");

            Ok(())
        })
    }
}

struct Renderer {
    target: RenderTarget,
    xsize: usize,
    ysize: usize,
    xpix: usize,
    ypix: usize,
    cell_ratio: f32,
    #[cfg(feature = "video")]
    last_frame: Option<gstreamer::Sample>,
    #[cfg(feature = "video")]
    position: usize,
    #[cfg(feature = "video")]
    duration: usize,
}

impl Renderer {
    fn new(
        target: RenderTarget,
        xsize: usize,
        ysize: usize,
        mut xpix: usize,
        mut ypix: usize,
        cell_ratio: f32,
    ) -> Renderer {
        #[cfg(feature = "sixel")]
        match std::env::var("TERM") {
            Ok(term) => {
                if term == "xterm" && target == RenderTarget::Sixel {
                    // xterm has a hard limit on graphics size
                    // maybe splitting the image into parts would work?
                    if xpix > 1000 {
                        xpix = 1000
                    };
                    if ypix > 1000 {
                        ypix = 1000
                    };
                }
            }
            _ => {}
        }

        Renderer {
            target,
            xsize,
            ysize,
            xpix,
            ypix,
            cell_ratio,
            #[cfg(feature = "video")]
            last_frame: None,
            #[cfg(feature = "video")]
            position: 0,
            #[cfg(feature = "video")]
            duration: 0,
        }
    }

    #[cfg(feature = "video")]
    fn set_widget_size(
        &mut self,
        xsize: usize,
        ysize: usize,
        xpix: usize,
        ypix: usize,
        cell_ratio: f32,
    ) -> MResult<()> {
        self.xsize = xsize;
        self.ysize = ysize;
        self.xpix = xpix;
        self.ypix = ypix;
        self.cell_ratio = cell_ratio;

        self.resend_scaled_frame()?;
        Ok(())
    }

    #[cfg(feature = "video")]
    fn send_media_meta(&self, frame: &impl ImgSize) -> MResult<()> {
        let (_, height) = self.max_size(frame);

        println!("{}", height + 1);
        println!("{}", self.position);
        println!("{}", self.duration);

        Ok(())
    }

    fn send_image(&self, image: &(impl WithRaw + ImgSize)) -> MResult<()> {
        self.target.send_image(image, &self)?;

        Ok(())
    }

    #[cfg(feature = "video")]
    fn new_frame(
        &mut self,
        frame: gstreamer::sample::Sample,
        position: usize,
        duration: usize,
    ) -> MResult<()> {
        self.position = position;
        self.duration = duration;

        self.target.send_image(&frame, &self)?;
        self.send_media_meta(&frame)?;

        self.last_frame = Some(frame);

        Ok(())
    }

    #[cfg(feature = "video")]
    fn resend_scaled_frame(&self) -> MResult<()> {
        use image::{ImageBuffer, Rgba};
        self.last_frame.as_ref().map(|frame| {
            let (xpix, ypix) = frame.size()?;
            frame.with_raw(|raw| {
                let img = ImageBuffer::<Rgba<u8>, Vec<u8>>::from_raw(
                    xpix as u32,
                    ypix as u32,
                    raw.to_vec(),
                )
                .ok_or(format_err!("Couldn't load last frame for rescaling!"))?;

                let img = DynamicImage::ImageRgba8(img);
                let (max_x, max_y) = self.max_size_pix(&img);
                let img = img
                    .resize_exact(max_x as u32, max_y as u32, image::FilterType::Gaussian)
                    .to_rgba();

                self.send_image(&img)?;
                self.send_media_meta(&img)?;
                Ok(())
            })
        });
        Ok(())
    }

    pub fn max_size(&self, image: &impl ImgSize) -> (usize, usize) {
        let xsize = self.xsize;
        let ysize = self.ysize;
        let (img_xsize, img_ysize) = image.size().unwrap();
        // Cells are not square, but almost 2:1
        let img_ratio = (img_xsize as f32 / img_ysize as f32) / self.cell_ratio;

        let (new_x, new_y) = fill_ratio(img_ratio, xsize, ysize);

        (new_x as usize, new_y as usize)
    }

    pub fn max_size_pix(&self, image: &impl ImgSize) -> (usize, usize) {
        let xsize = self.xpix;
        let ysize = self.ypix;
        let (img_xsize, img_ysize) = image.size().unwrap();
        let img_ratio = img_xsize as f32 / img_ysize as f32;

        let (new_x, mut new_y) = fill_ratio(img_ratio, xsize, ysize);

        if self.target == RenderTarget::Unicode {
            let rem = new_y % 2;
            new_y -= rem;
        }

        (new_x as usize, new_y as usize)
    }
}

fn fill_ratio(ratio: f32, max_x: usize, max_y: usize) -> (usize, usize) {
    let mut new_x;
    let mut new_y;

    // tall / slim
    if ratio < 1 as f32 {
        new_x = (max_y as f32 * ratio) as usize;
        new_y = max_y;
    // short / wide
    } else {
        new_x = max_x;
        new_y = (max_x as f32 / ratio) as usize;
    }

    // ensure it fits within max_x
    if new_x > max_x {
        new_x = max_x;
        new_y = (max_x as f32 / ratio) as usize;
    }

    // ensure it fits within max_y
    if new_y > max_y {
        new_y = max_y;
        new_x = (max_y as f32 * ratio) as usize;
    }

    (new_x, new_y)
}
